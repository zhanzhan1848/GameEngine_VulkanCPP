

// 法线分布函数
float DistributionGGX(vec3 N, vec3 H, float a)
{
	float a2 = a * a * a * a;
	float NdotH = max(dot(N, H), 0.0);
	float NdotH2 = NdotH * NdotH;

	float nom = a2;
	float denom = (NdotH2 * (a2 - 1.0) + 1.0);
	denom = 3.1415926535897932384626433832795 * denom * denom;

	return nom / denom;
}

// 几何函数
float GeometrySchlickGGX(float NdotV, float k)
{
	float r = k + 1.0;
	float a = (r * r) / 8.0;

	float nom = NdotV;
	float denom = NdotV * (1.0 - k) + k;

	return nom / denom;
}

float GeometrySmith(vec3 N, vec3 V, vec3 L, float k)
{
	float NdotV = max(dot(N, V), 0.0);
	float NdotL = max(dot(N, L), 0.0);
	float ggx1 = GeometrySchlickGGX(NdotV, k);
	float ggx2 = GeometrySchlickGGX(NdotL, k);

	return ggx1 * ggx2;
}

// 菲涅尔方程
vec3 fresnelSchlick(float cosTheta, vec3 F0)
{
	return F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);
}

// 光照计算
#define TILE_SIZE 16
#define NO_LIGHT_ATTENUATION 0
vec3 CalculateLighting(vec3 N, vec3 L, vec3 V, vec3 lightColor)
{
    float NdotL = dot(N, L);
    float specular = 0.0;

    if(NdotL > 0.0)
    {
        vec3 R = reflect(-L, N);
        float VdotR = max(dot(V, R), 0.0);
        specular = clamp(NdotL * pow(VdotR, 4.0) * 0.5, 0.0, 1.0);
    }

    return (max(0.0, NdotL) + specular) * lightColor; //
}

// 计算点光源对像素的光照贡献
vec3 PointLight(vec3 N, vec3 worldPos, vec3 V, LightParameters light)
{
    vec3 L = light.Position - worldPos;
    float dSq = dot(L, L);
    vec3 color = vec3(0.0);

#if NO_LIGHT_ATTENUATION
    if(dSq < (light.Range * light.Range))
    {
        float dRcp = inversesqrt(dSq);
        L *= dRcp;
        color = clamp(dot(N, L), 0.0, 1.0) * light.Color * light.Intensity * 0.2;
    }
#else
    if(dSq < (light.Range * light.Range))
    {
        float dRcp = inversesqrt(dSq);
        L *= dRcp;
        float attenuation = 1.0 - smoothstep(-light.Range, light.Range, 1.0 / dRcp);
        color = CalculateLighting(N, L, V, attenuation * light.Color * light.Intensity);
    }
#endif

    return color;
}

// 计算spot光源对像素的光照贡献
vec3 SpotLight(vec3 N, vec3 worldPos, vec3 V, LightParameters light)
{
    vec3 L = light.Position - worldPos;
    float dSq = dot(L, L);
    vec3 color = vec3(0.0);

#if NO_LIGHT_ATTENUATION
    if(dSq < (light.Range * light.Range))
    {
        float dRcp = inversesqrt(dSq);
        L *= dRcp;
        float CosAngleToLight = clamp(dot(-L, light.Direction), 0.0, 1.0);
        float angularAttenuation = float(light.CosPenumbra < CosAngleToLight);
        color = clamp(dot(N, L), 0.0, 1.0) * light.Color * light.Intensity * angularAttenuation * 0.2;
    }
#else
    if(dSq < (light.Range * light.Range))
    {
        float dRcp = inversesqrt(dSq);
        L *= dRcp;
        float attenuation = 1.0 - smoothstep(-light.Range, light.Range, 1.0 / dRcp);
        float CosAngleToLight = clamp(dot(-L, light.Direction), 0.0, 1.0);
        float angularAttenuation = smoothstep(light.CosPenumbra, light.CosUmbra, CosAngleToLight);
        color = CalculateLighting(N, L, V, attenuation * light.Color * light.Intensity * angularAttenuation);
    }
#endif

    return color;
}

// view to projection
vec4 projectToScreenSpace(vec3 point, mat4 projection)
{
	return projection * vec4(point, 1.0);
}

// world to view
vec3 projectToViewSpace(vec3 point, mat4 view)
{
	return (view * vec4(point, 1.0)).xyz;
}

// 计算像素距离
float distanceSquared(vec2 A, vec2 B)
{
	A -= B;
	return dot(A, A);
}

// 判断是否被遮挡
// bool query(vec2 z, vec2 uv, int width, int height)
// {
// 	float depths = texture(samplers[0], uv / vec2(width, height)).a;
// 	return z.y < depths && z.x > depths;
// }

// SSR
struct Result
{
	bool IsHit;

	vec2 UV;
	vec3 pos;

	int IterationCount;
};

struct Ray
{
	vec3 origin;
	vec3 direction;
};

// Result RayMarching(Ray r, int width, int height)
// {
// 	Result result;
// 	vec3 Begin = r.origin;
// 	vec3 End = r.origin + r.direction * 10000;
// 
// 	vec3 v0 = projectToViewSpace(Begin);
// 	vec3 v1 = projectToViewSpace(End);
// 
// 	vec4 H0 = projectToScreenSpace(v0);
// 	vec4 H1 = projectToScreenSpace(v1);
// 
// 	float k0 = 1.0 / H0.w;
// 	float k1 = 1.0 / H1.w;
// 
// 	vec3 Q0 = v0 * k0;
// 	vec3 Q1 = v1 * k1;
// 
// 	vec2 P0 = H0.xy * k0;
// 	vec2 P1 = H1.xy * k1;
// 
// 	vec2 Size = vec2(width, height);
// 	P0 = (P0 + 1) / 2 * Size;
// 	P1 = (P1 + 1) / 2 * Size;
// 
// 	P1 += vec2((distanceSquared(P0, P1) < 0.0001) ? 0.01 : 0.0);
// 	
// 	vec2 delta = P1 - P0;
// 	bool Permute = false;
// 	if(abs(delta.x) < abs(delta.y))
// 	{
// 		Permute = true;
// 		delta = delta.yx;
// 		P0 = P0.yx;
// 		P1 = P1.yx;
// 	}
// 	float stepDir = sign(delta.x);
// 	float invdx = stepDir / delta.x;
// 	vec3 dQ = (Q1 - Q0) * invdx;
// 	float dk = (k1 - k0) * invdx;
// 	vec2 dP = vec2(stepDir, delta.y * invdx);
// 	float stride = 1.0f;
// 
// 	dP *= stride; dQ *= stride; dk *= stride;
// 	P0 += dP; Q0 += dQ; k0 += dk;
// 
// 	int step = 0;
// 	int maxstep = 500;
// 	float k = k0;
// 	float endx = P1.x * stepDir;
// 	vec3 Q = Q0;
// 	float prevZMaxEstimate = v0.z;
// 
// 	for(vec2 P = P0; step < maxstep; step++, P += dP, Q.z += dQ.z, k += dk)
// 	{
// 		result.UV = Permute ? P.yx : P;
// 		vec2 Depths;
// 		Depths.x = prevZMaxEstimate;
// 		Depths.y = (dQ.z * 0.5 + Q.z) / (dk * 0.5 + k);
// 		prevZMaxEstimate = Depths.y;
// 		if(Depths.x < Depths.y)
// 		{
// 			Depths.xy = Depths.yx;
// 		}
// 		if(result.UV.x > 1600 || result.UV.x < 0 || result.UV.y > 900 || result.UV.y < 0)
// 		{
// 			break;
// 		}
// 		result.IsHit = query(Depths, result.UV, width, height);
// 		if(result.IsHit) { break; }
// 	}
// 
// 	return result;
// }


// Light Culling
// Check to see if a point is fully behind (inside the negative halfspace of) a plane
bool PointInsidePlane(vec3 p, Plane plane)
{
    return dot(plane.Normal, p) - plane.Distance < 0;
}

// Check to see if a sphere is fully behind (inside the negative halfspace of) a plane
// Source: Real-time collision detection, Christer Ericson(2005)
bool SphereInsidePlane(Sphere sphere, Plane plane)
{
    return dot(plane.Normal, sphere.Center) - plane.Distance < -sphere.Radius;
}

// Check to see if a cone if fully behind (inside the negative halfspace of) a plane
// Source:: Real-time collision detection, Christer Ericson(2005)
bool ConeInsidePlane(Cone cone, Plane plane)
{
    // Compute the farthest point on the end of the cone to the positive space of the plane
    vec3 m = cross(cross(plane.Normal, cone.Direction), cone.Direction);
    vec3 Q = cone.Tip + cone.Direction * cone.Height - m * cone.Radius;

    // The cone is in the negative halfspace of the plane if both
    // the tip of the cone and the farthest point on the end of the cone to the
    // positive halfspce of the plane are both inside the negative halfspace
    // of the plane
    return PointInsidePlane(cone.Tip, plane) && PointInsidePlane(Q, plane);
}

#if !USE_BOUNDING_SPHERES
// Check to see of a light is partially contained within the function
bool SphereInsideFrustum(Sphere sphere, Frustum frustum, float zNear, float zFar)
{
    // First check depth
    // Note: Here, the view vector points in the -Z axis so the
    // far depth value will be approaching -infinity.
    return !((sphere.Center.z - sphere.Radius > zNear || sphere.Center.z + sphere.Radius < zFar) ||
                SphereInsidePlane(sphere, frustum.Planes[0]) ||
                SphereInsidePlane(sphere, frustum.Planes[1]) ||
                SphereInsidePlane(sphere, frustum.Planes[2]) ||
                SphereInsidePlane(sphere, frustum.Planes[3]));
}

bool ConeInsideFrustum(Cone cone, Frustum frustum, float zNear, float zFar)
{
    bool result = true;

    Plane nearPlane = Plane(vec3(0, 0, -1), -zNear);
    Plane farPlane = Plane(vec3(0, 0, 1), zFar);

    // First check the near and far clipping planes
    if(ConeInsidePlane(cone, nearPlane) || ConeInsidePlane(cone, farPlane))
    {
        result = false;
    }

    // Then check frustum planes
    for(int i = 0; i < 4 && result; i++)
    {
        if(ConeInsidePlane(cone, frustum.Planes[i]))
        {
            result = false;
        }
    }
    return result;
}
#endif

Plane ComputePlane(vec3 p0, vec3 p1, vec3 p2)
{
	Plane plane;
	vec3 v0 = p1 - p0;
	vec3 v2 = p2 - p0;

	plane.Normal = normalize(cross(v0, v2));
	plane.Distance = dot(plane.Normal, p0);
	return plane;
}

// Converts a normalized screen-space position to a 3D coordinate depending on "inverse" parameter.
// UV is screen-space UV coordinate of the pixel
// depth is z-buffer depth
// inverse parameter can be
//          -   inverse projection                      ->  screen to view-space
//          -   inverse view_projection                 ->  screen to world-space
//          -   inverse world_view_projection           ->  screen to object-space
vec4 UnprojectUV(vec2 uv, float depth, mat4 inverse)
{
    // Convert to clip space
    vec4 clip = vec4(vec2(uv.x, 1.f - uv.y) * 2.f - 1.f, depth, 1.f);
    
    // 3D-space position (before perspective divide)
    vec4 position = inverse * clip;
    
    // Divide by w to get the 3D-space position
    return position / position.w;
}

vec4 ClipToView(vec4 clip, mat4 inverseProjection)
{
    // View space position
	vec4 view = inverseProjection * clip;
	// Perspective (un)projection
	return view /= view.w;
}

vec4 ScreenToView(vec4 screen, vec2 invViewDimensions, mat4 inverseProjection)
{
	vec2 texCoord = screen.xy * invViewDimensions;
	vec4 clip = vec4(vec2(texCoord.x, 1.0 - texCoord.y) * 2.0 - 1.0, screen.z, screen.w);
	return ClipToView(clip, inverseProjection);
}